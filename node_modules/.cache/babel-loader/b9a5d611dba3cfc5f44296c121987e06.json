{"ast":null,"code":"'use strict'; // this[BUFFER] is the remainder of a chunk if we're waiting for\n// the full 512 bytes of a header to come in.  We will Buffer.concat()\n// it to the next write(), which is a mem copy, but a small one.\n//\n// this[QUEUE] is a Yallist of entries that haven't been emitted\n// yet this can only get filled up if the user keeps write()ing after\n// a write() returns false, or does a write() with more than one entry\n//\n// We don't buffer chunks, we always parse them and either create an\n// entry, or push it into the active entry.  The ReadEntry class knows\n// to throw data away if .ignore=true\n//\n// Shift entry off the buffer when it emits 'end', and emit 'entry' for\n// the next one in the list.\n//\n// At any time, we're pushing body chunks into the entry at WRITEENTRY,\n// and waiting for 'end' on the entry at READENTRY\n//\n// ignored entries get .resume() called on them straight away\n\nvar _classCallCheck = require(\"C:\\\\Users\\\\suresoft\\\\Desktop\\\\vomproject\\\\sure-frontend\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"C:\\\\Users\\\\suresoft\\\\Desktop\\\\vomproject\\\\sure-frontend\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/createClass\");\n\nvar _inherits = require(\"C:\\\\Users\\\\suresoft\\\\Desktop\\\\vomproject\\\\sure-frontend\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/inherits\");\n\nvar _createSuper = require(\"C:\\\\Users\\\\suresoft\\\\Desktop\\\\vomproject\\\\sure-frontend\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/createSuper\");\n\nvar warner = require('./warn-mixin.js');\n\nvar Header = require('./header.js');\n\nvar EE = require('events');\n\nvar Yallist = require('yallist');\n\nvar maxMetaEntrySize = 1024 * 1024;\n\nvar Entry = require('./read-entry.js');\n\nvar Pax = require('./pax.js');\n\nvar zlib = require('minizlib');\n\nvar gzipHeader = Buffer.from([0x1f, 0x8b]);\nvar STATE = Symbol('state');\nvar WRITEENTRY = Symbol('writeEntry');\nvar READENTRY = Symbol('readEntry');\nvar NEXTENTRY = Symbol('nextEntry');\nvar PROCESSENTRY = Symbol('processEntry');\nvar EX = Symbol('extendedHeader');\nvar GEX = Symbol('globalExtendedHeader');\nvar META = Symbol('meta');\nvar EMITMETA = Symbol('emitMeta');\nvar BUFFER = Symbol('buffer');\nvar QUEUE = Symbol('queue');\nvar ENDED = Symbol('ended');\nvar EMITTEDEND = Symbol('emittedEnd');\nvar EMIT = Symbol('emit');\nvar UNZIP = Symbol('unzip');\nvar CONSUMECHUNK = Symbol('consumeChunk');\nvar CONSUMECHUNKSUB = Symbol('consumeChunkSub');\nvar CONSUMEBODY = Symbol('consumeBody');\nvar CONSUMEMETA = Symbol('consumeMeta');\nvar CONSUMEHEADER = Symbol('consumeHeader');\nvar CONSUMING = Symbol('consuming');\nvar BUFFERCONCAT = Symbol('bufferConcat');\nvar MAYBEEND = Symbol('maybeEnd');\nvar WRITING = Symbol('writing');\nvar ABORTED = Symbol('aborted');\nvar DONE = Symbol('onDone');\nvar SAW_VALID_ENTRY = Symbol('sawValidEntry');\nvar SAW_NULL_BLOCK = Symbol('sawNullBlock');\nvar SAW_EOF = Symbol('sawEOF');\n\nvar noop = function noop(_) {\n  return true;\n};\n\nmodule.exports = warner( /*#__PURE__*/function (_EE) {\n  _inherits(Parser, _EE);\n\n  var _super = _createSuper(Parser);\n\n  function Parser(opt) {\n    var _this;\n\n    _classCallCheck(this, Parser);\n\n    opt = opt || {};\n    _this = _super.call(this, opt);\n    _this.file = opt.file || ''; // set to boolean false when an entry starts.  1024 bytes of \\0\n    // is technically a valid tarball, albeit a boring one.\n\n    _this[SAW_VALID_ENTRY] = null; // these BADARCHIVE errors can't be detected early. listen on DONE.\n\n    _this.on(DONE, function (_) {\n      if (_this[STATE] === 'begin' || _this[SAW_VALID_ENTRY] === false) {\n        // either less than 1 block of data, or all entries were invalid.\n        // Either way, probably not even a tarball.\n        _this.warn('TAR_BAD_ARCHIVE', 'Unrecognized archive format');\n      }\n    });\n\n    if (opt.ondone) _this.on(DONE, opt.ondone);else {\n      _this.on(DONE, function (_) {\n        _this.emit('prefinish');\n\n        _this.emit('finish');\n\n        _this.emit('end');\n\n        _this.emit('close');\n      });\n    }\n    _this.strict = !!opt.strict;\n    _this.maxMetaEntrySize = opt.maxMetaEntrySize || maxMetaEntrySize;\n    _this.filter = typeof opt.filter === 'function' ? opt.filter : noop; // have to set this so that streams are ok piping into it\n\n    _this.writable = true;\n    _this.readable = false;\n    _this[QUEUE] = new Yallist();\n    _this[BUFFER] = null;\n    _this[READENTRY] = null;\n    _this[WRITEENTRY] = null;\n    _this[STATE] = 'begin';\n    _this[META] = '';\n    _this[EX] = null;\n    _this[GEX] = null;\n    _this[ENDED] = false;\n    _this[UNZIP] = null;\n    _this[ABORTED] = false;\n    _this[SAW_NULL_BLOCK] = false;\n    _this[SAW_EOF] = false;\n    if (typeof opt.onwarn === 'function') _this.on('warn', opt.onwarn);\n    if (typeof opt.onentry === 'function') _this.on('entry', opt.onentry);\n    return _this;\n  }\n\n  _createClass(Parser, [{\n    key: CONSUMEHEADER,\n    value: function value(chunk, position) {\n      var _this2 = this;\n\n      if (this[SAW_VALID_ENTRY] === null) this[SAW_VALID_ENTRY] = false;\n      var header;\n\n      try {\n        header = new Header(chunk, position, this[EX], this[GEX]);\n      } catch (er) {\n        return this.warn('TAR_ENTRY_INVALID', er);\n      }\n\n      if (header.nullBlock) {\n        if (this[SAW_NULL_BLOCK]) {\n          this[SAW_EOF] = true; // ending an archive with no entries.  pointless, but legal.\n\n          if (this[STATE] === 'begin') this[STATE] = 'header';\n          this[EMIT]('eof');\n        } else {\n          this[SAW_NULL_BLOCK] = true;\n          this[EMIT]('nullBlock');\n        }\n      } else {\n        this[SAW_NULL_BLOCK] = false;\n        if (!header.cksumValid) this.warn('TAR_ENTRY_INVALID', 'checksum failure', {\n          header: header\n        });else if (!header.path) this.warn('TAR_ENTRY_INVALID', 'path is required', {\n          header: header\n        });else {\n          var type = header.type;\n          if (/^(Symbolic)?Link$/.test(type) && !header.linkpath) this.warn('TAR_ENTRY_INVALID', 'linkpath required', {\n            header: header\n          });else if (!/^(Symbolic)?Link$/.test(type) && header.linkpath) this.warn('TAR_ENTRY_INVALID', 'linkpath forbidden', {\n            header: header\n          });else {\n            var entry = this[WRITEENTRY] = new Entry(header, this[EX], this[GEX]); // we do this for meta & ignored entries as well, because they\n            // are still valid tar, or else we wouldn't know to ignore them\n\n            if (!this[SAW_VALID_ENTRY]) {\n              if (entry.remain) {\n                // this might be the one!\n                var onend = function onend() {\n                  if (!entry.invalid) _this2[SAW_VALID_ENTRY] = true;\n                };\n\n                entry.on('end', onend);\n              } else this[SAW_VALID_ENTRY] = true;\n            }\n\n            if (entry.meta) {\n              if (entry.size > this.maxMetaEntrySize) {\n                entry.ignore = true;\n                this[EMIT]('ignoredEntry', entry);\n                this[STATE] = 'ignore';\n                entry.resume();\n              } else if (entry.size > 0) {\n                this[META] = '';\n                entry.on('data', function (c) {\n                  return _this2[META] += c;\n                });\n                this[STATE] = 'meta';\n              }\n            } else {\n              this[EX] = null;\n              entry.ignore = entry.ignore || !this.filter(entry.path, entry);\n\n              if (entry.ignore) {\n                // probably valid, just not something we care about\n                this[EMIT]('ignoredEntry', entry);\n                this[STATE] = entry.remain ? 'ignore' : 'header';\n                entry.resume();\n              } else {\n                if (entry.remain) this[STATE] = 'body';else {\n                  this[STATE] = 'header';\n                  entry.end();\n                }\n\n                if (!this[READENTRY]) {\n                  this[QUEUE].push(entry);\n                  this[NEXTENTRY]();\n                } else this[QUEUE].push(entry);\n              }\n            }\n          }\n        }\n      }\n    }\n  }, {\n    key: PROCESSENTRY,\n    value: function value(entry) {\n      var _this3 = this;\n\n      var go = true;\n\n      if (!entry) {\n        this[READENTRY] = null;\n        go = false;\n      } else if (Array.isArray(entry)) this.emit.apply(this, entry);else {\n        this[READENTRY] = entry;\n        this.emit('entry', entry);\n\n        if (!entry.emittedEnd) {\n          entry.on('end', function (_) {\n            return _this3[NEXTENTRY]();\n          });\n          go = false;\n        }\n      }\n\n      return go;\n    }\n  }, {\n    key: NEXTENTRY,\n    value: function value() {\n      var _this4 = this;\n\n      do {} while (this[PROCESSENTRY](this[QUEUE].shift()));\n\n      if (!this[QUEUE].length) {\n        // At this point, there's nothing in the queue, but we may have an\n        // entry which is being consumed (readEntry).\n        // If we don't, then we definitely can handle more data.\n        // If we do, and either it's flowing, or it has never had any data\n        // written to it, then it needs more.\n        // The only other possibility is that it has returned false from a\n        // write() call, so we wait for the next drain to continue.\n        var re = this[READENTRY];\n        var drainNow = !re || re.flowing || re.size === re.remain;\n\n        if (drainNow) {\n          if (!this[WRITING]) this.emit('drain');\n        } else re.once('drain', function (_) {\n          return _this4.emit('drain');\n        });\n      }\n    }\n  }, {\n    key: CONSUMEBODY,\n    value: function value(chunk, position) {\n      // write up to but no  more than writeEntry.blockRemain\n      var entry = this[WRITEENTRY];\n      var br = entry.blockRemain;\n      var c = br >= chunk.length && position === 0 ? chunk : chunk.slice(position, position + br);\n      entry.write(c);\n\n      if (!entry.blockRemain) {\n        this[STATE] = 'header';\n        this[WRITEENTRY] = null;\n        entry.end();\n      }\n\n      return c.length;\n    }\n  }, {\n    key: CONSUMEMETA,\n    value: function value(chunk, position) {\n      var entry = this[WRITEENTRY];\n      var ret = this[CONSUMEBODY](chunk, position); // if we finished, then the entry is reset\n\n      if (!this[WRITEENTRY]) this[EMITMETA](entry);\n      return ret;\n    }\n  }, {\n    key: EMIT,\n    value: function value(ev, data, extra) {\n      if (!this[QUEUE].length && !this[READENTRY]) this.emit(ev, data, extra);else this[QUEUE].push([ev, data, extra]);\n    }\n  }, {\n    key: EMITMETA,\n    value: function value(entry) {\n      this[EMIT]('meta', this[META]);\n\n      switch (entry.type) {\n        case 'ExtendedHeader':\n        case 'OldExtendedHeader':\n          this[EX] = Pax.parse(this[META], this[EX], false);\n          break;\n\n        case 'GlobalExtendedHeader':\n          this[GEX] = Pax.parse(this[META], this[GEX], true);\n          break;\n\n        case 'NextFileHasLongPath':\n        case 'OldGnuLongPath':\n          this[EX] = this[EX] || Object.create(null);\n          this[EX].path = this[META].replace(/\\0.*/, '');\n          break;\n\n        case 'NextFileHasLongLinkpath':\n          this[EX] = this[EX] || Object.create(null);\n          this[EX].linkpath = this[META].replace(/\\0.*/, '');\n          break;\n\n        /* istanbul ignore next */\n\n        default:\n          throw new Error('unknown meta: ' + entry.type);\n      }\n    }\n  }, {\n    key: \"abort\",\n    value: function abort(error) {\n      this[ABORTED] = true;\n      this.emit('abort', error); // always throws, even in non-strict mode\n\n      this.warn('TAR_ABORT', error, {\n        recoverable: false\n      });\n    }\n  }, {\n    key: \"write\",\n    value: function write(chunk) {\n      var _this5 = this;\n\n      if (this[ABORTED]) return; // first write, might be gzipped\n\n      if (this[UNZIP] === null && chunk) {\n        if (this[BUFFER]) {\n          chunk = Buffer.concat([this[BUFFER], chunk]);\n          this[BUFFER] = null;\n        }\n\n        if (chunk.length < gzipHeader.length) {\n          this[BUFFER] = chunk;\n          return true;\n        }\n\n        for (var i = 0; this[UNZIP] === null && i < gzipHeader.length; i++) {\n          if (chunk[i] !== gzipHeader[i]) this[UNZIP] = false;\n        }\n\n        if (this[UNZIP] === null) {\n          var ended = this[ENDED];\n          this[ENDED] = false;\n          this[UNZIP] = new zlib.Unzip();\n          this[UNZIP].on('data', function (chunk) {\n            return _this5[CONSUMECHUNK](chunk);\n          });\n          this[UNZIP].on('error', function (er) {\n            return _this5.abort(er);\n          });\n          this[UNZIP].on('end', function (_) {\n            _this5[ENDED] = true;\n\n            _this5[CONSUMECHUNK]();\n          });\n          this[WRITING] = true;\n\n          var _ret = this[UNZIP][ended ? 'end' : 'write'](chunk);\n\n          this[WRITING] = false;\n          return _ret;\n        }\n      }\n\n      this[WRITING] = true;\n      if (this[UNZIP]) this[UNZIP].write(chunk);else this[CONSUMECHUNK](chunk);\n      this[WRITING] = false; // return false if there's a queue, or if the current entry isn't flowing\n\n      var ret = this[QUEUE].length ? false : this[READENTRY] ? this[READENTRY].flowing : true; // if we have no queue, then that means a clogged READENTRY\n\n      if (!ret && !this[QUEUE].length) this[READENTRY].once('drain', function (_) {\n        return _this5.emit('drain');\n      });\n      return ret;\n    }\n  }, {\n    key: BUFFERCONCAT,\n    value: function value(c) {\n      if (c && !this[ABORTED]) this[BUFFER] = this[BUFFER] ? Buffer.concat([this[BUFFER], c]) : c;\n    }\n  }, {\n    key: MAYBEEND,\n    value: function value() {\n      if (this[ENDED] && !this[EMITTEDEND] && !this[ABORTED] && !this[CONSUMING]) {\n        this[EMITTEDEND] = true;\n        var entry = this[WRITEENTRY];\n\n        if (entry && entry.blockRemain) {\n          // truncated, likely a damaged file\n          var have = this[BUFFER] ? this[BUFFER].length : 0;\n          this.warn('TAR_BAD_ARCHIVE', \"Truncated input (needed \".concat(entry.blockRemain, \" more bytes, only \").concat(have, \" available)\"), {\n            entry: entry\n          });\n          if (this[BUFFER]) entry.write(this[BUFFER]);\n          entry.end();\n        }\n\n        this[EMIT](DONE);\n      }\n    }\n  }, {\n    key: CONSUMECHUNK,\n    value: function value(chunk) {\n      if (this[CONSUMING]) this[BUFFERCONCAT](chunk);else if (!chunk && !this[BUFFER]) this[MAYBEEND]();else {\n        this[CONSUMING] = true;\n\n        if (this[BUFFER]) {\n          this[BUFFERCONCAT](chunk);\n          var c = this[BUFFER];\n          this[BUFFER] = null;\n          this[CONSUMECHUNKSUB](c);\n        } else this[CONSUMECHUNKSUB](chunk);\n\n        while (this[BUFFER] && this[BUFFER].length >= 512 && !this[ABORTED] && !this[SAW_EOF]) {\n          var _c = this[BUFFER];\n          this[BUFFER] = null;\n          this[CONSUMECHUNKSUB](_c);\n        }\n\n        this[CONSUMING] = false;\n      }\n      if (!this[BUFFER] || this[ENDED]) this[MAYBEEND]();\n    }\n  }, {\n    key: CONSUMECHUNKSUB,\n    value: function value(chunk) {\n      // we know that we are in CONSUMING mode, so anything written goes into\n      // the buffer.  Advance the position and put any remainder in the buffer.\n      var position = 0;\n      var length = chunk.length;\n\n      while (position + 512 <= length && !this[ABORTED] && !this[SAW_EOF]) {\n        switch (this[STATE]) {\n          case 'begin':\n          case 'header':\n            this[CONSUMEHEADER](chunk, position);\n            position += 512;\n            break;\n\n          case 'ignore':\n          case 'body':\n            position += this[CONSUMEBODY](chunk, position);\n            break;\n\n          case 'meta':\n            position += this[CONSUMEMETA](chunk, position);\n            break;\n\n          /* istanbul ignore next */\n\n          default:\n            throw new Error('invalid state: ' + this[STATE]);\n        }\n      }\n\n      if (position < length) {\n        if (this[BUFFER]) this[BUFFER] = Buffer.concat([chunk.slice(position), this[BUFFER]]);else this[BUFFER] = chunk.slice(position);\n      }\n    }\n  }, {\n    key: \"end\",\n    value: function end(chunk) {\n      if (!this[ABORTED]) {\n        if (this[UNZIP]) this[UNZIP].end(chunk);else {\n          this[ENDED] = true;\n          this.write(chunk);\n        }\n      }\n    }\n  }]);\n\n  return Parser;\n}(EE));","map":null,"metadata":{},"sourceType":"script"}